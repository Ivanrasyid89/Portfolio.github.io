# -*- coding: utf-8 -*-
"""Classification of Heart Disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1khpfVhRW1aYZWd795XmKe4JJtyIzKgw2

# **IMPORT LIBRARY**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

"""# **DATA**"""

# Membaca data
data = pd.read_csv("heart_statlog_cleveland_hungary_final.csv")
# Menampilkan jumlah baris dan kolom
print(data.shape)

"""# **EKSPLORATORY DATA ANALYSIS**"""

# Menampilkan informasi data
data.info()

# Menampilkan data awal
data.head()

"""**Visualisasi Data Numerik**"""

## Menampilkan histogram ##
# Membuat objek gambar
plt.figure(figsize=(10,6))
# Kolom numerik
kolom_numerik = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
# Looping for untuk mendapatkan indeks fitur dengan nilai kolomnya
for i, column in enumerate(kolom_numerik):
  # Membuat subplot dengan ukuran 2 baris 3 kolom
  plt.subplot(2,3,i+1)
  # Membuat histogram
  sns.histplot(data = data, x = column, kde = True)
  # Menampilkan judul subplot
  plt.title(column, fontsize = 12)
  plt.xlabel('Frekuensi')
  plt.ylabel('')
  # Mengatur tata letak subplot
  plt.tight_layout();

## Membuat boxplot ##
# Membuat objek gambar
plt.figure(figsize=(10, 6))
# Kolom numerik
kolom_numerik = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
# Looping for untuk mendapatkan indeks fitur dengan nilai kolomnya
for i, column in enumerate(kolom_numerik):
    # Membuat subplot dengan ukuran 2 baris 3 kolom
    plt.subplot(2, 3, i + 1)
    # Membuat boxplot
    sns.boxplot(data=data, y=column, color='skyblue')
    plt.title(column, fontsize=12)
    plt.xlabel('')
    plt.ylabel(column, fontsize=10)
    plt.tight_layout()

"""**Visualisasi Data Kategorik**"""

## Membuat diagram batang ##
# Kolom kategorik
kolom_kategorik = ['sex', 'chest pain type', 'fasting blood sugar', 'resting ecg', 'exercise angina', 'ST slope']
# Daftar warna plot
colors = ['skyblue', 'salmon', 'lightgreen', 'orange', 'lightcoral', 'cornflowerblue']
# Looping for untuk mendapatkan indeks fitur dengan nilai kolomnya
for i, column in enumerate(kolom_kategorik):
    plt.subplot(2, 3, i + 1)
    if column == 'exercise angina':
        # Membuat diagram batang
        data[column].value_counts().plot(kind='bar', color=colors)
    else:
        # Membuat diagram batang
        data[column].value_counts().plot(kind='bar', color=colors)
    plt.title(column, fontsize=12)
    plt.ylabel('Count')
    plt.tight_layout()

"""**Visualisasi Target**"""

## Membuat pie chart ##
# Membuat objek gambar
plt.figure(figsize=(3, 3))
# Membuat pie chart
data['target'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90, colors=['skyblue', 'salmon'])
plt.title('target', fontsize=12)
plt.ylabel('')
plt.tight_layout()
plt.show()

"""**Korelasi**"""

## Plot korelasi ##
# Daftar variabel numerik
variabel_numerik = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
# Daftar variabel kategorikal
variabel_kategorik = ['sex', 'chest pain type', 'fasting blood sugar', 'resting ecg', 'exercise angina', 'ST slope']
# Gabungan variabel
variables = variabel_numerik + variabel_kategorik
# Korelasi antara variabel numerik dan target
kor = data[variables + ['target']].corr()
# Plot heatmap dari korelasi
plt.figure(figsize=(10, 8))
# Membuat plot korelasi
sns.heatmap(kor.loc[variabel_numerik + ['target'], variables], annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Korelasi antara Fitur dan Target')
plt.show()

"""# **DATA PREPROCESSING**

**Data Cleaning**
"""

# Menampilkan ringkasan data
data.describe()

# Mengganti nilai yang negatif dengan rata-rata
data.loc[data['oldpeak'] < 0, 'oldpeak'] = data['oldpeak'].mean()
# Mengganti nilai 'ST slope' yang sama dengan 0 dengan nilai yang paling umum
most_common_ST_slope = data['ST slope'].mode()[0]
data.loc[data['ST slope'] == 0, 'ST slope'] = most_common_ST_slope
data.describe()

"""**Missing Value**"""

# Memeriksa jumlah missing value di setiap kolom
missing_values = data.isnull().sum()
print(missing_values)

"""**Standarisasi Data**"""

## Standarisasi data (mean = 0 dan st.dev = 1) ##
# Mendefinisikan fungsi scale data
def scale_data(data):
    # Membuat salinan data
    scaled_data = data.copy()
    # Fitur numerik yang diskalakan
    fitur_numerik = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
    # Melakukan standarisasi
    scaler = StandardScaler()
    # Mengubah skala nilai
    scaled_data[fitur_numerik] = scaler.fit_transform(scaled_data[fitur_numerik])
    return scaled_data
# Menampilkan data hasil standarisasi
scaled_data = scale_data(data)
print(scaled_data)

## Standarisasi data ##
# Mendefinisikan fungsi scale data
def scale_data(data):
    # Membuat salinan data
    scaled_data = data.copy()
    # Fitur numerik yang akan diskalakan
    fitur_numerik = ['age', 'resting bp s', 'cholesterol', 'max heart rate', 'oldpeak']
    # Iterasi melalui setiap fitur numerik
    for feature in fitur_numerik:
        # Menghitung rata-rata dari fitur
        mean = np.mean(data[feature])
        # Menghitung standar deviasi dari fitur
        std_dev = np.std(data[feature])
        # Standarisasi nilai pada fitur
        scaled_data[feature] = (data[feature] - mean) / std_dev
    return scaled_data
# Menampilkan data hasil standarisasi
scaled_data = scale_data(data)
print(scaled_data)

"""**Partisi Data**"""

## Split data ke dalam fitur (X) dan target (Y) ##
# Split data yang telah distandarisasi
# Fitur X tanpa kolom target
X = scale_data(data.drop('target', axis=1))
# Target Y
y = scaled_data['target']

# Menampilkan fitur X
X

# Menampilkan fitur y
y

## Partisi data ##
# Partisi data ke dalam data latih (80%) dan data uji (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)
# Menampilkan dimensi data
print(f"X_train : {X_train.shape}")
print(f"X_test : {X_test.shape}")
print(f"y_train : {y_train.shape}")
print(f"y_test : {y_test.shape}")

# Menampilkan fitur X sebagai data latih
X_train

# Menampilkan target y sebagai data latih
y_train

# Menampilkan fitur X sebagai data uji
X_test

# Menampilkan target y sebagai data uji
y_test

"""# **MODELLING**

# **K-Nearest Neighbors**

**Menentukan Nilai k**
"""

## Menentukan nilai k menggunakan akar dari banyaknya observasi ##
# Fungsi untuk menghitung nilai k
def hitung_k(data):
    # Menghitung jumlah observasi dalam data training
    n = len(X_train)
    # Menentukan nilai k dengan mengambil akar dari jumlah observasi
    k = int(np.sqrt(n))
    return k
# Mendefinisikan data
data = [X_train]
# Menghitung k
k = hitung_k(data)
# Menampilkan k
print("Nilai k yang ditentukan:", k)

"""**Melatih Model**"""

## Membangun model KNN ##
# Membuat model KNN menggunakan k optimal dan jarak euclidean
model_knn = KNeighborsClassifier(n_neighbors = k, weights='uniform', algorithm='auto', metric='euclidean')
# Melatih model KNN menggunakan data latih
model_knn.fit(X_train, y_train)

"""**Evaluasi Model**"""

## Mengevaluasi model KNN ##
# Menguji model KNN menggunakan data uji (X_test)
y_pred = model_knn.predict(X_test)
# Menghitung metrik evaluasi: akurasi, presisi, recall, dan F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
# Menampilkan metrik evaluasi
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

## Menghitung metrik evaluasi ##
# Menghitung jumlah prediksi yang benar
correct_predictions = np.sum(y_pred == y_test)
# Menghitung total jumlah prediksi
total_predictions = len(y_test)
# Menghitung akurasi
accuracy = correct_predictions / total_predictions

# Menghitung true positives, false positives, true negatives, dan false negatives
# Menghitung jumlah positif benar
true_positives = np.sum((y_pred == 1) & (y_test == 1))
# Menghitung jumlah positif salah
false_positives = np.sum((y_pred == 1) & (y_test == 0))
# Menghitung jumlah negatif benar
true_negatives = np.sum((y_pred == 0) & (y_test == 0))
# Menghitung jumlah negatif salah
false_negatives = np.sum((y_pred == 0) & (y_test == 1))

# Menghitung presisi, recall, dan F1 score
precision = true_positives / (true_positives + false_positives)
recall = true_positives / (true_positives + false_negatives)
f1 = 2 * (precision * recall) / (precision + recall)

# Menampilkan metrik evaluasi
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

# Menampilkan prediksi
y_pred

# Confusion Matrix
cm_knn = confusion_matrix(y_test, model_knn.predict(X_test))
print("Confusion Matrix KNN:")
print(cm_knn)

# Laporan Klasifikasi (Classification Report)
cr_knn = classification_report(y_test, model_knn.predict(X_test))
print("\nClassification Report KNN:")
print(cr_knn)

# Kurva ROC
knn_roc_auc = roc_auc_score(y_test, model_knn.predict(X_test))
fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, model_knn.predict(X_test))
roc_auc = auc(fpr_knn, tpr_knn)
plt.figure()
plt.plot(fpr_knn, tpr_knn, label = 'K-Nearest Neighbors'%knn_roc_auc)
plt.plot([0, 1], [0, 1], 'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive')
plt.ylabel('True Positive')
plt.title('ROC MODEL KNN')
plt.legend(loc = "lower right")
plt.show()
print(f"\nAUC-Skor ROC: {round(roc_auc*100, 2)}%")

"""**Prediksi**"""

## Prediksi data baru ##
# Data yang diprediksi
Data = [[40, 1, 1, 140, 237, 1, 0, 150, 1, 1.0, 2]]
# Melakukan prediksi berdasarkan data, hasilnya disimpan dalam Y_pred
Y_pred = model_knn.predict(Data)
# Mencetak hasil
print("Hasil Prediksi : Penyakit Jantung", Y_pred)
# Hasil 0 : Normal
# Hasil 1 : Penyakit Jantung

## Prediksi manual ##
# Membuat data baru dalam bentuk array
data_baru = np.array([[40, 1, 1, 140, 237, 1, 0, 150, 1, 1.0, 2]])
# 1. Memilih banyaknya tetangga (k = 30)
k = k
# 2. Menghitung jarak titik data baru dengan data lama (X_train) menggunakan jarak Euclidean
jarak_euclidean = np.sqrt(np.sum((X_train - data_baru) ** 2, axis=1))
# 3. Mengambil k terdekat
indeks_terdekat = np.argsort(jarak_euclidean)[:k]
# 4. Menghtung jumlah titik data dalam setiap kategori di antara 30 tetangga terdekat
jumlah_kelas_0 = np.sum(y_train.iloc[indeks_terdekat] == 0)
jumlah_kelas_1 = np.sum(y_train.iloc[indeks_terdekat] == 1)
# 5. Menetapkan data baru ke dalam kategori yang memiliki jumlah tetangga terbanyak
hasil_prediksi = 1 if jumlah_kelas_1 > jumlah_kelas_0 else 0
# Cetak hasil prediksi
if hasil_prediksi == 0:
    print("Hasil Prediksi : Normal")
else:
    print("Hasil Prediksi : Penyakit Jantung")

"""# **Support Vector Machine**

**Melatih Model**
"""

## Membangun model SVM ##
# Membuat model SVM
modelsvm = SVC()
# Melakukan tuning parameter
param_grid = {
    'C': [0.1, 1, 10, 100],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto'],
    'degree': [2, 3, 4]
}
grid_search = GridSearchCV(modelsvm, param_grid, cv=5)
# Menemukan kombinasi parameter optimal
grid_search.fit(X_train, y_train)
# Kombinasi parameter optimal
best_svm = grid_search.best_estimator_
# Menampilkan parameter optimal
print('Kombinasi parameter optimal:',  grid_search.best_params_)

## Tuning parameter ##
# Inisialisasi daftar parameter yang akan diuji
C_values = [0.1, 1, 10, 100]
kernel_values = ['linear', 'rbf', 'poly']
gamma_values = ['scale', 'auto']
degree_values = [2, 3, 4]

# Inisialisasi variabel untuk menyimpan parameter terbaik dan akurasi terbaik
best_params = {}
best_accuracy = 0.0

# Inisialisasi objek KFold untuk validasi silang
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Inisialisasi variabel untuk menyimpan akurasi dari setiap iterasi
all_accuracies = []

# Melakukan iterasi untuk setiap kombinasi parameter
for C in C_values:
    for kernel in kernel_values:
        for gamma in gamma_values:
            for degree in degree_values:
                # Inisialisasi model SVM dengan parameter tertentu
                modelsvm = SVC(C=C, kernel=kernel, gamma=gamma, degree=degree)
                accuracies = []
                # Melakukan validasi silang
                for train_index, val_index in kf.split(X_train):
                    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]
                    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]
                    # Melatih model pada setiap lipatan
                    modelsvm.fit(X_train_fold, y_train_fold)
                    # Mengukur akurasi pada setiap lipatan
                    y_pred_fold = modelsvm.predict(X_val_fold)
                    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)
                    accuracies.append(accuracy_fold)
                # Menghitung rata-rata akurasi dari semua lipatan
                mean_accuracy = np.mean(accuracies)
                # Memeriksa apakah akurasi yang dihasilkan lebih baik dari yang sebelumnya
                if mean_accuracy > best_accuracy:
                    best_accuracy = mean_accuracy
                    best_params = {'C': C, 'kernel': kernel, 'gamma': gamma, 'degree': degree}
                # Menyimpan akurasi dari setiap iterasi
                all_accuracies.append({'C': C, 'kernel': kernel, 'gamma': gamma, 'degree': degree, 'accuracy': mean_accuracy})

# Menampilkan parameter terbaik
print('Kombinasi parameter optimal:', best_params)

# Menampilkan akurasi dari setiap iterasi
print("Akurasi dari setiap iterasi:")
for i, acc in enumerate(all_accuracies, 1):
    print(f"Iterasi {i}: C={acc['C']}, kernel={acc['kernel']}, gamma={acc['gamma']}, degree={acc['degree']}, Accuracy={acc['accuracy']}")

"""**Evaluasi Model**"""

## Mengevaluasi model SVM ##
# Menguji model menggunakan data uji (X_test)
y_pred = best_svm.predict(X_test)
# Menghitung metrik evaluasi: akurasi, presisi, recall, dan F1 score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
# Menampilkan metrik evaluasi
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

# Menampilkan prediksi
y_pred

# Confusion Matrix
cm_svm = confusion_matrix(y_test, modelsvm.predict(X_test))
print("Confusion Matrix SVM:")
print(cm_svm)

# Laporan Klasifikasi (Classification Report)
cr_svm = classification_report(y_test, modelsvm.predict(X_test))
print("\nClassification Report SVM:")
print(cr_svm)

# Kurva ROC
svm_roc_auc = roc_auc_score(y_test, modelsvm.predict(X_test))
fpr_svm, tpr_svm, thresholds_svm = roc_curve(y_test, modelsvm.predict(X_test))
roc_auc = auc(fpr_svm, tpr_svm)
plt.figure()
plt.plot(fpr_svm, tpr_svm, label = 'Support Vector Machine'%svm_roc_auc)
plt.plot([0, 1], [0, 1], 'r--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive')
plt.ylabel('True Positive')
plt.title('ROC MODEL SVM')
plt.legend(loc = "lower right")
plt.show()
print(f"\nAUC-Skor ROC: {round(roc_auc*100, 2)}%")

"""**Prediksi**"""

## Prediksi data baru ##
# Data yang diprediksi
Data = [[40, 1, 1, 140, 237, 1, 0, 150, 1, 1.0, 2]]
# Melakukan prediksi berdasarkan data, hasilnya disimpan dalam Y_pred
Y_pred = best_svm.predict(Data)
# Mencetak hasil
print("Hasil Prediksi : Penyakit Jantung", Y_pred)
# Hasil 0 : Normal
# Hasil 1 : Penyakit Jantung

## Prediksi manual ##
# Menghitung koefisien lagrange sebagai parameter bobot (w)
alpha = best_svm.dual_coef_
# Menghitung support vector (xi)
support_vectors = best_svm.support_vectors_
# Menghitung bias (b)
bias = best_svm.intercept_
# Menampilkan parameter
print("Alpha (Koefisien Lagrange):", alpha)
print("Support Vectors (xi):", support_vectors)
print("Bias (w):", bias)

# Mengakses data latih
X_train
# Menampilkan xi (support vectors)
print("Support Vectors (xi):")
for i, vector in enumerate(support_vectors):
    print("x_{}: {}".format(i, vector))
# Menampilkan yi (kelas target)
print("Labels (yi):", y_train)

## Fungsi kernel ##
# Kernel yang digunakan
kernel = best_svm.kernel
print("Fungsi kernel SVM:", kernel)
# Menampilkan parameter internal
gamma = best_svm._gamma
print("Parameter gamma:", gamma)

# Mendefinisikan fungsi untuk menghitung nilai kernel antara fitur dan terget
def fungsi_kernel(X, Y):
    if kernel == 'rbf':
        # Rumus fungsi kernel RBF
        return np.exp(-gamma * np.linalg.norm(X - Y) ** 2)
    elif kernel == 'linear':
        # Rumus fungsi kernel linear
        return np.dot(X, Y.T)
    elif kernel == 'poly':
        # Rumus fungsi kernel polynomial
        return (gamma * np.dot(X, Y.T) + 1) ** best_svm.degree
# Menghitung nilai prediksi
# Mendefinisikan fungsi prediksi
def prediksi(data_baru):
    # Melakukan inisialisasi
    hasil_prediksi = bias
    # Looping for untuk melakukan prediksi
    for i in range(len(alpha[0])):
        # Menghitung prediksi
        hasil_prediksi += alpha[0][i] * best_svm.dual_coef_[0][i] * fungsi_kernel(support_vectors[i], data_baru)
    return np.sign(hasil_prediksi).astype(int)
# Melakukan prediksi
Y_pred = prediksi(data_baru)
print("Hasil Prediksi : Penyakit Jantung:", Y_pred)