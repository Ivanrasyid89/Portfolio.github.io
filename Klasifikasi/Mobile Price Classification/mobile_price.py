# -*- coding: utf-8 -*-
"""Mobile Price.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i-sSILmYEu-K9RL_JQUvtX0cWEZbjaUV

# **IMPORT LIBRARY**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Split dataset
from sklearn.model_selection import train_test_split
# Standardscaller
from sklearn.preprocessing import StandardScaler
# Cross validation
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
# Evaluation metric
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc
# Tuning parameter
from sklearn.model_selection import GridSearchCV
# Logistic Regression
from sklearn.linear_model import LogisticRegression
# Decision Tree
from sklearn.tree import DecisionTreeClassifier
# Random Forest
from sklearn.ensemble import RandomForestClassifier

"""# **IMPORT DATA**

## **Read Data**
"""

data_train = pd.read_csv("train.csv")

data_train.head()

data_test = pd.read_csv("test.csv")

data_test.head()

"""## **Data Information**"""

data_train.info()

"""Berdasarkan output, dapat dilihat bahwa tidak ada data yang hilang, karena semua variabel terdiri dari 2000 entri."""

data_test.info()

"""# **EXPLORATORY DATA ANALYSIS (EDA)**

## **Data Distribution**
"""

# List numerical column
col_num = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt',
           'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']

# Create boxplot
plt.figure(figsize=(15,10))
for i, column in enumerate(col_num):
  plt.subplot(4,4,i+1)
  sns.boxplot(data = data_train, y=column, color='skyblue')
  plt.title(column, fontsize = 12)
  plt.xlabel('')
  plt.ylabel('')
  plt.tight_layout();

# List categorical column
col_cat = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']

colors = ['skyblue', 'salmon', 'lightgreen', 'orange']

# Bar plot for col_cat using label 0: yes, 1:no
plt.figure(figsize=(15, 8))
for i, column in enumerate(col_cat):
    plt.subplot(2, 4, i + 1)
    # Count the occurrences of each unique value and plot as a bar chart
    data_train[column].value_counts().sort_index().plot(kind='bar', color=colors)
    plt.title(column, fontsize=12)
    plt.xlabel('0: No, 1: Yes')
    plt.ylabel('Count')
    plt.xticks(rotation=0)
    for j, value in enumerate(data_train[column].value_counts().sort_index()):
        plt.text(j, value, str(value), ha='center', va='top')
    plt.tight_layout()
plt.show()

# Pie chart for price range column
plt.figure(figsize=(10, 10))
plt.pie(data_train['price_range'].value_counts(), labels=['Low Cost', 'Medium Cost', 'High Cost', 'Very High Cost'],
        autopct='%1.1f%%', startangle=90, colors=['skyblue', 'salmon', 'lightgreen', 'orange'])
plt.title('Price Range')
plt.show()

"""Berdasarkan output, dapat dilihat bahwa semua kelas memiliki jumlah instance yang seimbang. Hal ini berarti bahwa data tersebut seimbang.

## **Correlation**
"""

# List numerical column
col_num = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt',
           'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']
# List categorical column
col_cat = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']
# Merge column
variables = col_num + col_cat

# Correlation
cor = data_train[variables + ['price_range']].corr()

# Heatmap
plt.figure(figsize=(20, 15))
sns.heatmap(cor.loc[col_num + ['price_range'], variables], annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Plot')
plt.show()

"""# **DATA PREPROCESSING**

## **Standardization**
"""

def scale_data(data_train, data_test, num_cols):
    # Copy to avoid changing original data
    scaled_data_train = data_train.copy()
    scaled_data_test = data_test.copy()

    # Initialize scaler
    scaler = StandardScaler()

    # Fit on training data and transform both
    scaled_data_train[num_cols] = scaler.fit_transform(data_train[num_cols])
    scaled_data_test[num_cols] = scaler.transform(data_test[num_cols])

    return scaled_data_train, scaled_data_test, scaler

num_features = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt',
           'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']

scaled_train, scaled_test, scaler = scale_data(data_train, data_test, num_features)

print(scaled_train)

print(scaled_test)

"""# **SPLIT DATA**"""

X = scaled_train.drop('price_range', axis=1)
y = scaled_train['price_range']

X

y

# Train test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1234)
print(f"X_train : {X_train.shape}")
print(f"X_test : {X_test.shape}")
print(f"y_train : {y_train.shape}")
print(f"y_test : {y_test.shape}")

X_train

X_test

y_train

y_test

"""# **MODELLING**"""

# pipeline
from sklearn.pipeline import Pipeline

"""## **Logistic Regression**"""

# Define pipeline
lr_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('lr', LogisticRegression())
])

# Define params
lr_param = {
    'lr__penalty': ['l2'],
    'lr__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],
    'lr__solver': ['lbfgs', 'newton-cg', 'newton-cholesky']
}

# Hyperparameter tuning
grid_search_lr = GridSearchCV(estimator=lr_pipeline, param_grid=lr_param, cv=5, scoring='accuracy')
grid_search_lr.fit(X_train, y_train)
print("Best parameters: ", grid_search_lr.best_params_)
print("Best score: ", grid_search_lr.best_score_)

# Best model
best_model_lr = grid_search_lr.best_estimator_

# Accuracy
print('Accuracy: ', best_model_lr.score(X_test, y_test))

"""## **Decision Tree Classifier**"""

# Define pipeline
dt_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('dt', DecisionTreeClassifier())
])

# Define params
dt_param = {
    'dt__criterion': ['gini', 'entropy'],
    'dt__max_depth': [2, 3, 5],
    'dt__min_samples_leaf': [5, 10, 20],
    'dt__min_samples_split': [2, 5, 10]
}

# Hyperparameter tuning
grid_search_dt = GridSearchCV(estimator=dt_pipeline, param_grid=dt_param, cv=5, scoring='accuracy')
grid_search_dt.fit(X_train, y_train)
print("Best parameters: ", grid_search_dt.best_params_)
print("Best score: ", grid_search_dt.best_score_)

# Best model
best_model_dt = grid_search_dt.best_estimator_

# Accuracy
print('Accuracy: ', best_model_dt.score(X_test, y_test))

"""## **Random Forest Classifier**"""

# Define pipeline
rf_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('rf', RandomForestClassifier())
])

# Define params
rf_param = {
    'rf__n_estimators': [10, 25, 30],
    'rf__max_depth': [2, 3, 5],
    'rf__min_samples_leaf': [5, 10, 20],
    'rf__min_samples_split': [2, 5, 10]
}

# Hyperparameter tuning
grid_search_rf = GridSearchCV(estimator=rf_pipeline, param_grid=rf_param, cv=5, scoring='accuracy')
grid_search_rf.fit(X_train, y_train)
print("Best parameters: ", grid_search_rf.best_params_)
print("Best score: ", grid_search_rf.best_score_)

# Best model
best_model_rf = grid_search_rf.best_estimator_

# Accuracy
print('Accuracy: ', best_model_rf.score(X_test, y_test))

"""## **Table Comparison**"""

model = ['Logistic Regression',
         'Decision Tree Classifier',
         'Random Forest Classifier']

best_score = [grid_search_lr.best_score_*100,
              grid_search_dt.best_score_*100,
              grid_search_rf.best_score_*100]

best_accuracy = [best_model_lr.score(X_test, y_test)*100,
                 best_model_dt.score(X_test, y_test)*100,
                 best_model_rf.score(X_test, y_test)*100]

data = {'Model': model, 'Best Score': best_score, 'Best Accuracy': best_accuracy}

df = pd.DataFrame(data)
df

"""Based on the output above, it can be seen that the Logistic Regression model is the best model. The parameters used to train the model have a value of 97.25%, which is the same as the accuracy when training the model.

# **MODEL EVALUATION**

## **Logistic Regression**
"""

y_pred_lr = best_model_lr.predict(X_test)
y_pred_lr

y_pred_probs_lr = best_model_lr.predict_proba(X_test)
y_pred_probs_lr

print(f'Accuracy: {accuracy_score(y_test, y_pred_lr)*100}')
print(f'Precision: {precision_score(y_test, y_pred_lr, average="macro")*100}')
print(f'Recall: {recall_score(y_test, y_pred_lr, average="macro")*100}')
print(f'F1 score: {f1_score(y_test, y_pred_lr, average="macro")*100}')

"""Berdasarkan output evaluasi:
- Dari 400 data yang diprediksi, model mampu memprediksi 389 data dengan benar, sehingga akurasi model adalah 97,25%. Ini berarti hanya 11 prediksi yang tidak sesuai dengan label yang sebenarnya.
- Presisi model sebesar 97,25% menunjukkan bahwa dari semua prediksi yang dibuat untuk setiap kelas, sekitar 97,25% sesuai dengan kelas aslinya, sedangkan 2,75% tidak sesuai dengan kelas aslinya. Ini berarti bahwa model tersebut **jarang memberikan** label yang salah (False Positive).
- Recall model sebesar 97,24% menunjukkan bahwa dari semua data yang sebenarnya termasuk dalam setiap kelas, model mengidentifikasi dengan benar sekitar 97,24%, sedangkan 2,76% tidak dapat diidentifikasi. Ini berarti bahwa model **jarang melewatkan** data yang seharusnya diidentifikasi (False Negative).
-Dengan nilai F1 sebesar 97.24%, menunjukkan bahwa presisi dan recall seimbang, sehingga model tidak hanya akurat dalam prediksi, tetapi juga konsisten dalam mengenali semua kelas.
"""

cm_lr = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm_lr, annot=True, fmt='g', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()

"""Berdasarkan plot konfusi matriks di atas:
- Untuk kelas 0, model berhasil mengklasifikasikan 92 dari 93 data dengan benar dan hanya 1 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 1.
- Untuk kelas 1, model berhasil mengklasifikasikan 98 dari 102 data dengan benar dan hanya 4 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 0 dan kelas 2.
- Untuk kelas 2, model berhasil mengklasifikasikan 93 dari 98 data dengan benar dan hanya 5 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 1 dan kelas 3. Selain itu, 4 data dari kelas 1 dan 3 juga salah diprediksi sebagai kelas 2.
- Untuk kelas 3, model berhasil mengklasifikasikan 106 dari 107 data dengan benar dan hanya 1 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 2. Selain itu, 2 data dari kelas 2 juga salah diprediksi sebagai kelas 3.
"""

cr_lr = classification_report(y_test, y_pred_lr)
print(cr_lr)

lr_roc_auc = roc_auc_score(y_test, y_pred_probs_lr, multi_class='ovr')
print('ROC AUC score:', lr_roc_auc)

"""Model memiliki kemampuan yang sangat baik dalam membedakan antar kelas. Dengan AUC sebesar 99,89%, kemungkinan besar prediksi model dapat membedakan data antar kategori dengan tingkat akurasi yang sangat tinggi"""

fpr = {}
tpr = {}
roc_auc = {}

for i in range(4):  # 4 CLASS
    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_probs_lr[:, i], pos_label=i)
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot ROC
plt.figure()
colors = ['blue', 'red', 'green', 'orange']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Logistic Regression')
plt.legend(loc="lower right")
plt.show()

"""## **Decision Tree Classifier**"""

y_pred_dt = best_model_dt.predict(X_test)
y_pred_dt

y_pred_probs_dt = best_model_dt.predict_proba(X_test)
y_pred_probs_dt

print(f'Accuracy: {accuracy_score(y_test, y_pred_dt)*100}')
print(f'Precision: {precision_score(y_test, y_pred_dt, average="macro")*100}')
print(f'Recall: {recall_score(y_test, y_pred_dt, average="macro")*100}')
print(f'F1 score: {f1_score(y_test, y_pred_dt, average="macro")*100}')

"""Berdasarkan output evaluasi:
- Dari 400 data yang diprediksi, model mampu memprediksi 337 data dengan benar, sehingga akurasi model adalah 84,25%. Ini berarti bahwa 63 prediksi yang tidak sesuai dengan label yang sebenarnya.
- Presisi model sebesar 84,16% menunjukkan bahwa dari semua prediksi yang dibuat untuk setiap kelas, sekitar 84,16% sesuai dengan kelas aslinya, sedangkan 15,84% tidak sesuai dengan kelas aslinya. Ini berarti bahwa model sedikit memberikan label yang salah (False Positive).
- Recall model sebesar 84,31% menunjukkan bahwa dari semua data yang sebenarnya termasuk ke dalam kelas, model mengidentifikasi dengan benar sekitar 84,31%, sedangkan 15,69% tidak dapat diidentifikasi. Ini berarti bahwa model sedikit melewaktkan data yang seharusnya diidentifikasi (False Negative).
- Dengan nilai f1 sebesar 84,22% menunjukkan bahwa presisi dan recall seimbang. Ini berarti bahwa model tidak hanya akurat dalam prediksi, tetapi juga konsisten dalam mengenali semua kelas.
"""

cm_dt = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm_dt, annot=True, fmt='g', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()

"""Berdasarkan plot konfusi matriks di atas:
- Untuk kelas 0, model berhasil mengklasifikasikan 88 dari 93 data dengan benar dan hanya 5 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 1. Selain itu, 8 data dari kelas 1 juga salah diprediksi sebagai kelas 0.
- Untuk kelas 1, model berhasil mengklasifikasikan 84 dari 102 data dengan benar dan hanya 18 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 0 dan kelas 2. Selain itu, 16 data dari kelas 0 dan kelas 2 juga salah diprediksi sebagai kelas 1.
- Untuk kelas 2, model berhasil mengklasifikasikan 71 dari 98 data dengan benar dan hanya 27 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 1 dan kelas 3. Selain itu, 14 data dari kelas 1 dan kelas 3 juga salah diprediksi sebagai kelas 2.
- Untuk kelas 3, model berhasil mengklasifikasikan 94 dari 107 data dengan benar dan hanya 13 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 2. Selain itu, 16 data dari kelas 2 juga salah diprediksi sebagai kelas 3.
"""

cr_dt = classification_report(y_test, y_pred_dt)
print(cr_dt)

lr_roc_auc = roc_auc_score(y_test, y_pred_probs_dt, multi_class='ovr')
print('ROC AUC score:', lr_roc_auc)

"""Model memiliki kemampuan yang sangat baik dalam membedakan antar kelas. Dengan AUC sebesar 95,35%, kemungkinan besar prediksi model dapat membedakan data antar kategori dengan tingkat akurasi yang sangat tinggi"""

fpr = {}
tpr = {}
roc_auc = {}

for i in range(4):  # 4 CLASS
    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_probs_dt[:, i], pos_label=i)
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot ROC
plt.figure()
colors = ['blue', 'red', 'green', 'orange']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Decision Tree Classifier')
plt.legend(loc="lower right")
plt.show()

"""## **Random Forest Classifier**"""

y_pred_rf = best_model_rf.predict(X_test)
y_pred_rf

y_pred_probs_rf = best_model_rf.predict_proba(X_test)
y_pred_probs_rf

print(f'Accuracy: {accuracy_score(y_test, y_pred_rf)*100}')
print(f'Precision: {precision_score(y_test, y_pred_rf, average="macro")*100}')
print(f'Recall: {recall_score(y_test, y_pred_rf, average="macro")*100}')
print(f'F1 score: {f1_score(y_test, y_pred_rf, average="macro")*100}')

"""Berdasarkan output evaluasi:

- Dari 400 data yang diprediksi, model mampu memprediksi 333 data dengan benar, sehingga akurasi model adalah 83,25%. Ini berarti bahwa ada 67 prediksi yang tidak sesuai dengan label yang sebenarnya.
- Presisi model sebesar 82,61% menunjukkan bahwa dari semua prediksi yang dibuat untuk setiap kelas, sekitar 82,61% sesuai dengan kelas aslinya, sedangkan 17,39% tidak sesuai dengan kelas aslinya. Ini berarti bahwa model sedikit memberikan label yang salah (False Positive).
- Recall model sebesar 83,32% menunjukkan bahwa dari semua data yang sebenarnya termasuk ke dalam kelas, model mengidentifikasi dengan benar sekitar 83,32%, sedangkan 16,68% tidak dapat diidentifikasi. Ini berarti bahwa model sedikit melewaktkan data yang seharusnya diidentifikasi (False Negative).
- Dengan nilai f1 sebesar 84,79% menunjukkan bahwa presisi dan recall seimbang. Ini berarti bahwa model tidak hanya akurat dalam prediksi, tetapi juga konsisten dalam mengenali semua kelas.
"""

cm_rf = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm_rf, annot=True, fmt='g', cmap='Blues')
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()

"""Berdasarkan plot konfusi matriks di atas:
- Untuk kelas 0, model berhasil mengklasifikasikan 93 dari 93 data dengan benar. Selain itu, 12 data dari kelas 1 salah diprediksi sebagai kelas 0.
- Untuk kelas 1, model berhasil mengklasifikasikan 71 dari 102 data dengan benar dan hanya 31 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 0 dan kelas 2. Selain itu, 21 data dari kelas 2 juga salah diprediksi sebagai kelas 1.
- Untuk kelas 2, model berhasil mengklasifikasikan 67 dari 98 data dengan benar dan hanya 31 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 1 dan kelas 3. Selain itu, 24 data dari kelas 1 dan kelas 3 juga salah diprediksi sebagai kelas 2.
- Untuk kelas 3, model berhasil mengklasifikasikan 102 dari 107 data dengan benar dan hanya 5 data yang salah diklasifikasikan ke kelas lain, yaitu kelas 2. Selain itu, 10 data dari kelas 2 juga salah diprediksi sebagai kelas 3.
"""

cr_rf = classification_report(y_test, y_pred_rf)
print(cr_rf)

lr_roc_auc = roc_auc_score(y_test, y_pred_probs_rf, multi_class='ovr')
print('ROC AUC score:', lr_roc_auc)

"""Model memiliki kemampuan yang sangat baik dalam membedakan antar kelas. Dengan AUC sebesar 95,56%, kemungkinan besar prediksi model dapat membedakan data antar kategori dengan tingkat akurasi yang sangat tinggi"""

fpr = {}
tpr = {}
roc_auc = {}

for i in range(4):  # 4 CLASS
    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_probs_rf[:, i], pos_label=i)
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot ROC
plt.figure()
colors = ['blue', 'red', 'green', 'orange']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Random Forest Classifier')
plt.legend(loc="lower right")
plt.show()

"""## **Table Comparison**"""

score_comparison = pd.DataFrame({
    'Model': ['Logistic Regression', 'Decision Tree Classifier', 'Random Forest Classifier'],
    'Accuracy': [accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_dt), accuracy_score(y_test, y_pred_rf)],
    'Precision': [precision_score(y_test, y_pred_lr, average="macro"), precision_score(y_test, y_pred_dt, average="macro"), precision_score(y_test, y_pred_rf, average="macro")],
    'Recall': [recall_score(y_test, y_pred_lr, average="macro"), recall_score(y_test, y_pred_dt, average="macro"), recall_score(y_test, y_pred_rf, average="macro")],
    'F1 Score': [f1_score(y_test, y_pred_lr, average="macro"), f1_score(y_test, y_pred_dt, average="macro"), f1_score(y_test, y_pred_rf, average="macro")],
    'ROC AUC Score': [roc_auc_score(y_test, y_pred_probs_lr, multi_class='ovr'), roc_auc_score(y_test, y_pred_probs_dt, multi_class='ovr'), roc_auc_score(y_test, y_pred_probs_rf, multi_class='ovr')]
})
score_comparison

"""Berdasarkan output di atas, model Regresi Logistik adalah model terbaik untuk mengklasifikasikan harga ponsel

# **PREDICTION**
"""

scaled_test.drop('id', axis=1, inplace=True)

scaled_test

prediction = best_model_lr.predict(scaled_test)

prediction

data_prediction = pd.DataFrame({
    "id": scaled_test.index,
    "price_range": prediction
})

price_range_mapping = {
    0: 'Low Cost',
    1: 'Medium Cost',
    2: 'High Cost',
    3: 'Very High Cost'
}

data_prediction['price_range'] = data_prediction['price_range'].map(price_range_mapping)

print(data_prediction)

# PIE CHART FOR PREDICTION
plt.figure(figsize=(10, 10))
plt.pie(data_prediction['price_range'].value_counts(), labels=data_prediction['price_range'].unique(),
        autopct='%1.1f%%', startangle=90, colors=['skyblue', 'salmon', 'lightgreen', 'orange'])
plt.title('Price Range Prediction')
plt.show()

"""- Berdasarkan plot tersebut dapat diketahui bahwa proporsi ponsel yang diklasifikasikan sebagai "Very High Cost" dan "High Cost" memiliki proporsi yang paling tinggi. Ini berarti bahwa dari 1000 data yang diprediksi, ada sebanyak 259 ponsel diklasifikasikan ke dalam masing-masing harga tersebut.
- Kemudian diikuti oleh ponsel yang diklasifikasikan sebagai "Medium Cost". Ini berarti bahwa ada sebanyak 250 ponsel diklasifikasikan ke dalam harga tersebut.
- Terdapat sebanyak 232 ponsel diklasifikasikan ke dalam "Low Cost"
"""