# -*- coding: utf-8 -*-
"""Mobile Price Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DHcnU9xTE9KlNdadPMJM79CjmNuYwp7u

# **IMPORT LIBRARY**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# Split dataset
from sklearn.model_selection import train_test_split
# Standarisasi fitur
from sklearn.preprocessing import StandardScaler, LabelBinarizer
# Validasi silang
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
# Metrik evaluasi
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc
# Tuning parameter
from sklearn.model_selection import GridSearchCV
# XGBOOST
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
# TensorFlow
import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam

"""# **DATA**"""

# Membaca data
data_train = pd.read_csv("train.csv")
data_test = pd.read_csv("test.csv")
# Menampilkan jumlah baris dan kolom
print(data_train.shape)
print(data_test.shape)

"""# **EXPLORATORY DATA ANALYSIS**

## Missing Value
"""

data_train.isnull().sum()

"""## Data Information"""

# Menampilkan informasi data
data_train.info()

# Menampilkan data awal
data_train.head()

"""## Box-plot"""

## Menampilkan boxplot ##
# Membuat objek gambar
plt.figure(figsize=(15,10))
# Kolom numerik
kolom_numerik = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'talk_time']
# Looping for untuk mendapatkan indeks fitur dengan nilai kolomnya
for i, column in enumerate(kolom_numerik):
  # Membuat subplot dengan ukuran 3 baris 4 kolom
  plt.subplot(4,4,i+1)
  # Membuat boxplot
  sns.boxplot(data=data_train, y=column, color='skyblue')
  # Menampilkan judul subplot
  plt.title(column, fontsize = 12)
  plt.xlabel('Frekuensi')
  plt.ylabel('')
  # Mengatur tata letak subplot
  plt.tight_layout();

"""## Bar-plot"""

## Menampilkan diagram batang ##
# Kolom kategorik
kolom_kategorik = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi', 'price_range']
# Daftar warna plot
colors = ['skyblue', 'salmon', 'lightgreen', 'orange']
# Looping for untuk mendapatkan indeks fitur dengan nilai kolomnya
for i, column in enumerate(kolom_kategorik):
    plt.subplot(2, 4, i + 1)
    # Membuat diagram batang
    data_train[column].value_counts().plot(kind='bar', color=colors)
    plt.title(column, fontsize=12)
    plt.ylabel('Count')
    plt.tight_layout()

"""## Correlation"""

## Plot korelasi ##
# Daftar variabel numerik
variabel_numerik = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'talk_time']
# Daftar variabel kategorikal
variabel_kategorik = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']
# Gabungan variabel
variables = variabel_numerik + variabel_kategorik
# Korelasi antara variabel numerik dan target
kor = data_train[variables + ['price_range']].corr()
# Plot heatmap dari korelasi
plt.figure(figsize=(20, 15))
# Membuat plot korelasi
sns.heatmap(kor.loc[variabel_numerik + ['price_range'], variables], annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Korelasi antara Fitur dan Target')
plt.show()

"""# **DATA PREPROCESSING**

## Standardize
"""

## Standarisasi data (mean = 0 dan st.dev = 1) ##
# Mendefinisikan fungsi scale data
def scale_data(data_train):
    # Membuat salinan data
    scaled_data_train = data_train.copy()
    # Fitur numerik yang diskalakan
    fitur_numerik = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'talk_time']
    # Melakukan standarisasi
    scaler = StandardScaler()
    # Mengubah skala nilai
    scaled_data_train[fitur_numerik] = scaler.fit_transform(scaled_data_train[fitur_numerik])
    return scaled_data_train
# Menampilkan data hasil standarisasi
scaled_data_train = scale_data(data_train)
print(scaled_data_train)

"""## Feature Engineering"""

# Pembuatan kolom fitur untuk masing masing kolom numerik dan kategorik
kolom_fitur = []

# Fitur Numerik:
fitur_numerik = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'talk_time']

for col in fitur_numerik:
  kolom_fitur_numerik = tf.feature_column.numeric_column(col)
  kolom_fitur.append(kolom_fitur_numerik)

# Fitur Kategorik:
fitur_kategorik = ['blue', 'dual_sim', 'four_g', 'three_g', 'touch_screen', 'wifi']

for col in fitur_kategorik:
    kolom_fitur_kategorik = tf.feature_column.categorical_column_with_vocabulary_list(
        key=col,
        vocabulary_list=scaled_data_train[col].unique().tolist()
    )
    kolom_fitur_kategorik_onehot = tf.feature_column.indicator_column(kolom_fitur_kategorik)
    kolom_fitur.append(kolom_fitur_kategorik_onehot)

# Pembuatan lapisan fitur sebagai input untuk model NN
feature_layer = tf.keras.layers.DenseFeatures(kolom_fitur)

# Konversi dataframe ke dataset Tensorflow
def data_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('price_range')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe),labels))

  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))

  ds = ds.batch(batch_size=batch_size)

  return ds

"""## Split Data"""

## Partisi Data untuk model NN ##
train, test = train_test_split(scaled_data_train, test_size=0.2, random_state=42)

# Konversi dataframe train dan test ke dataset tfds
train_ds = data_to_dataset(train, shuffle = True, batch_size=32)
test_ds = data_to_dataset(test, shuffle=False, batch_size=32)

## Split data ke dalam fitur (X) dan target (Y) ##
# Fitur X
X = scale_data(data_train.drop('price_range', axis=1))
# Target Y
y = scaled_data_train['price_range']

X

y

## Partisi data ##
# Partisi data ke dalam data latih (80%) dan data uji (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)
# Menampilkan dimensi data
print(f"X_train : {X_train.shape}")
print(f"X_test : {X_test.shape}")
print(f"y_train : {y_train.shape}")
print(f"y_test : {y_test.shape}")

X_train

y_train

X_test

y_test

"""# **MODELLING**

## NEURAL NETWORK
"""

## Membangun Model NN ##
model = tf.keras.Sequential([
    feature_layer,
    tf.keras.layers.Dense(units=512, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(units=256, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(units=128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    tf.keras.layers.Dense(units=64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    tf.keras.layers.Dense(units=4, activation='softmax')  # 4 kelas untuk 'price_range'
])

# Kompilasi Model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Latih model
history = model.fit(train_ds, validation_data=test_ds, epochs=20)

"""## XGBOOST"""

model_xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
param_grid = {
    'learning_rate': [0.1, 0.01, 0.001],
    # Kedalaman tiap pohon
    'max_depth': [3, 5, 7],
    # Jumlah pohon keputusan
    'n_estimator': [100, 200, 300],
    # Banyak sampel dalam proses boosting
    'subsample': [0.6, 0.8, 1.0],
    # Jumlah minimum sampel
    'min_child_weight': [1, 3, 5]
}
# GridSearchCV untuk menemukan parameter optimal
grid_search = GridSearchCV(model_xgb, param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)

# Kombinasi parameter optimal
best_xgb = grid_search.best_estimator_

# Menampilkan parameter optimal
print('Kombinasi parameter optimal:', grid_search.best_params_)

"""# **MODEL EVALUATION**

## NEURAL NETWORK

### Accuracy
"""

accuracy = model.evaluate(test_ds)
print(f'Accuracy: {accuracy}')

"""### Predict"""

# Prediksi menggunakan model NN
y_pred_probs_nn = model.predict(test_ds)
y_pred_nn = tf.argmax(y_pred_probs_nn, axis=1)

"""### Evaluation Metric"""

# Menghitung metrik evaluasi: akurasi, presisi, recall, dan F1 score
accuracy_nn = accuracy_score(y_test, y_pred_nn)
precision_nn = precision_score(y_test, y_pred_nn, average='weighted')
recall_nn = recall_score(y_test, y_pred_nn, average='weighted')
f1_nn = f1_score(y_test, y_pred_nn, average='weighted')
# Menampilkan metrik evaluasi
print("Accuracy:", accuracy_nn)
print("Precision:", precision_nn)
print("Recall:", recall_nn)
print("F1 Score:", f1_nn)

"""### Confussion Matrix"""

# Confusion Matrix
cm_nn = confusion_matrix(y_test, y_pred_nn)
print("Confusion Matrix NN:")
print(cm_nn)

"""### Classification Report"""

# Laporan Klasifikasi (Classification Report)
cr_nn = classification_report(y_test, y_pred_nn)
print("\nClassification Report NN:")
print(cr_nn)

"""### ROC Score"""

# Menghitung ROC AUC untuk masing-masing kelas
roc_auc_scores = roc_auc_score(y_test, y_pred_probs_nn, multi_class='ovo')
print("ROC AUC Score:", roc_auc_scores)

# Plot Kurva ROC
plt.figure()
colors = ['blue', 'red', 'green', 'orange']
for i in range(4):
    fpr, tpr, _ = roc_curve(y_test, y_pred_probs_nn[:, i], pos_label=i)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC MODEL NN')
plt.legend(loc='lower right')
plt.show()

"""## XGBOOST

### Evaluation Metric
"""

## Mengevaluasi model XGBOOST ##
# Menguji model menggunakan data uji (X_test)
y_pred_xgb = best_xgb.predict(X_test)
# Menghitung metrik evaluasi: akurasi, presisi, recall, dan F1 score
accuracy = accuracy_score(y_test, y_pred_xgb)
precision = precision_score(y_test, y_pred_xgb, average='weighted')
recall = recall_score(y_test, y_pred_xgb, average='weighted')
f1 = f1_score(y_test, y_pred_xgb, average='weighted')
# Menampilkan metrik evaluasi
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

"""### Confussion Matrix"""

# Confusion Matrix
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
print("Confusion Matrix XGBOOST:")
print(cm_xgb)

"""### Classification Report"""

# Laporan Klasifikasi (Classification Report)
cr_xgb = classification_report(y_test, y_pred_xgb)
print("\nClassification Report XGBOOST:")
print(cr_xgb)

"""### Predict"""

# Prediksi peluang tiap kelas
y_pred_probs_xgb = best_xgb.predict_proba(X_test)

"""### ROC Score"""

# Skor ROC untuk kasus multiclass
xgb_roc_auc = roc_auc_score(y_test, y_pred_probs_xgb, multi_class='ovr')
print(f'ROC AUC Score: {xgb_roc_auc}')

# Menghitung ROC setiap kelas
fpr = {}
tpr = {}
roc_auc = {}

for i in range(4):  # 4 kelas
    fpr[i], tpr[i], _ = roc_curve(y_test, y_pred_probs_xgb[:, i], pos_label=i)
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot kurva ROC
plt.figure()
colors = ['blue', 'red', 'green', 'orange']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (area = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC MODEL XGBOOST')
plt.legend(loc="lower right")
plt.show()

"""# **PREDICTION**

## Read Data
"""

data_testing = pd.read_csv("test.csv")

"""## Data Preprocessing"""

## Standarisasi data (mean = 0 dan st.dev = 1) ##
# Mendefinisikan fungsi scale data
def scale_data(data_testing):
    # Membuat salinan data
    scaled_data_testing = data_testing.copy()
    # Fitur numerik yang diskalakan
    fitur_numerik = ['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'talk_time']
    # Melakukan standarisasi
    scaler = StandardScaler()
    # Mengubah skala nilai
    scaled_data_testing[fitur_numerik] = scaler.fit_transform(scaled_data_testing[fitur_numerik])
    return scaled_data_testing
# Menampilkan data hasil standarisasi
scaled_data_testing = scale_data(data_testing)
print(scaled_data_testing)

"""## NEURAL NETWORK

### Data Convertion
"""

# Mengonversi dataframe ke dataset TensorFlow
def data_to_dataset(dataframe, batch_size=32):
    dataframe = dataframe.copy()
    ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))
    ds = ds.batch(batch_size)
    return ds

test_ds = data_to_dataset(scaled_data_testing)

"""### Predict"""

# Prediksi menggunakan model NN
y_pred_probs_nn = model.predict(test_ds)
y_pred_nn = tf.argmax(y_pred_probs_nn, axis=1).numpy()

# Menampilkan prediksi
print("Prediksi NN:")
print(y_pred_nn)

"""## XGBOOST

### Preparing Data
"""

data_predict = scaled_data_testing[['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g', 'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g', 'touch_screen', 'wifi']]

data_predict.head()

"""### Predict"""

# Prediksi menggunakan model XGBoost
y_pred_xgb = best_xgb.predict(data_predict)

# Menampilkan prediksi
print("Prediksi XGBoost:")
print(y_pred_xgb)